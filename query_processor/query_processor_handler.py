# # handlers/query_processor_handler.py
# todo it was working using old text handler
# import os
# import joblib
# import numpy as np
# from typing import Dict

# from text_processing.text_processing_handler import TextProcessor, process_text_pipeline
# from utils.config import OUTPUT_DIR
# from tfidf_representation.tfidf_handler import TfIdfHandler
# class QueryProcessorHandler:
#     """
#     ÙŠØ¹Ø§Ù„Ø¬ Ø¹Ù…Ù„ÙŠØ§Øª ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª.
#     """
#     def __init__(self, dataset_name: str, model_type: str):
#         self.dataset_name = dataset_name
#         self.model_type = model_type
#         self.text_processor = TextProcessor()
#         self._load_vectorizer()

#     def _get_vectorizer_path(self) -> str:
#         """
#         ÙŠØ¨Ù†ÙŠ Ø§Ù„Ù…Ø³Ø§Ø± Ù„Ù…Ù„Ù Ø§Ù„Ù€ vectorizer Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù‡ÙŠÙƒÙ„ÙŠØ© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©.
#         """
#         # Ù‡Ø°Ø§ Ø§Ù„Ù…Ù†Ø·Ù‚ ØµØ­ÙŠØ­ ÙˆÙŠØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ù„Ù‡ÙŠÙƒÙ„ÙŠØ© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
#         model_specific_dir = os.path.join(OUTPUT_DIR, self.dataset_name, self.model_type)
        
#         # Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ù…ÙˆØ­Ø¯ Ø§Ù„Ø¢Ù† ÙˆÙ‡Ùˆ 'vectorizer.joblib'
#         return os.path.join(model_specific_dir, "vectorizer.joblib")

#     def _load_vectorizer(self):
#         """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù€ vectorizer Ø£Ùˆ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¶Ù…ÙŠÙ† ÙÙ‚Ø·."""
#         vectorizer_path = self._get_vectorizer_path()
#         print(f"ğŸ“‚ Loading vectorizer from: {vectorizer_path}")
#         self.vectorizer = joblib.load(vectorizer_path)
#         print("âœ… Vectorizer loaded successfully.")

#     def process(self, query: str) -> np.ndarray:
#         """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©: ØªØ¹Ø§Ù„Ø¬ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… ÙˆØªØ­ÙˆÙ„Ù‡ Ø¥Ù„Ù‰ Ù…ØªØ¬Ù‡."""
#         print(f"ğŸ“ Processing query for model '{self.model_type}': '{query}'")
        
#         # ===== ÙŠØ¨Ø¯Ø£ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ù‡Ù†Ø§ =====

#         if self.model_type == 'tfidf':
#             # Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©: Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¨Ø´ÙƒÙ„ Ù…Ù†ÙØµÙ„ Ù„ØºØ±Ø¶ Ø§Ù„Ø·Ø¨Ø§Ø¹Ø© ÙÙ‚Ø·
#             # Ø§Ù„Ù€ vectorizer Ø³ÙŠÙ‚ÙˆÙ… Ø¨Ù†ÙØ³ Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¯Ø§Ø®Ù„ÙŠØ§Ù‹
#             processed_query_display = process_text_pipeline(query, self.text_processor)
#             print(f"âœ… Query after processing: '{processed_query_display}'")
            
#             query_vector = self.vectorizer.transform([query])
#             return query_vector.toarray().tolist() # ØªØ­ÙˆÙŠÙ„ Ù„Ù…ØµÙÙˆÙØ© ÙƒØ«ÙŠÙØ© Ø«Ù… Ù‚Ø§Ø¦Ù…Ø© Ù„Ø¥Ø±Ø³Ø§Ù„Ù‡Ø§ ÙƒÙ€ JSON

#         elif self.model_type == 'bert':
#             processed_query = process_text_pipeline(query, self.text_processor)
            
#             # Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©: Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¨Ø¹Ø¯ Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡
#             print(f"âœ… Query after processing: '{processed_query}'")

#             query_vector = self.vectorizer.encode([processed_query], normalize_embeddings=True)
#             return query_vector.tolist() # ØªØ­ÙˆÙŠÙ„ Ù„Ù€ list Ù„Ø¥Ø±Ø³Ø§Ù„Ù‡Ø§ ÙƒÙ€ JSON
        
#         # ===== ÙŠÙ†ØªÙ‡ÙŠ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ù‡Ù†Ø§ =====
        
#         raise NotImplementedError("Model type not implemented")
# handlers/query_processor_handler.py
# handlers/query_processor_handler.py
import os
import joblib
import numpy as np
from typing import Dict, List

# --- Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„ÙƒÙ„Ø§Ø³ ÙÙ‚Ø·ØŒ ÙˆÙ„ÙŠØ³ Ø§Ù„Ø¯Ø§Ù„Ø© ---
from text_processing.text_processing_handler import TextProcessingHandler
# handlers/query_processor_handler.py
import os
import joblib
import numpy as np
from typing import Dict, List

from text_processing.text_processing_handler import TextProcessingHandler
from utils.config import OUTPUT_DIR
from utils.logger_config import logger

class QueryProcessorHandler:
    """
    Processes a raw query into a vector and returns the spell-corrected
    version of the query for display purposes.
    """
    # --- Ø§Ù„Ø¢Ù† ÙŠØ³ØªÙ‚Ø¨Ù„ ÙƒØ§Ø¦Ù† Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø¬Ø§Ù‡Ø² ---
    def __init__(self, dataset_name: str, model_type: str, text_processor: TextProcessingHandler):
        self.dataset_name = dataset_name
        self.model_type = model_type
        # --- Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø°ÙŠ ØªÙ… ØªÙ…Ø±ÙŠØ±Ù‡ ---
        self.text_processor = text_processor
        self.vectorizer = self._load_vectorizer()

    def _get_vectorizer_path(self) -> str:
        model_specific_dir = os.path.join(OUTPUT_DIR, self.dataset_name, self.model_type)
        return os.path.join(model_specific_dir, "vectorizer.joblib")

    def _load_vectorizer(self):
        vectorizer_path = self._get_vectorizer_path()
        logger.info(f"ğŸ“‚ Loading vectorizer from: {vectorizer_path}")
        if not os.path.exists(vectorizer_path):
            raise FileNotFoundError(f"Vectorizer not found at {vectorizer_path}. Please build the representation first.")
        return joblib.load(vectorizer_path)

    def process(self, query: str) -> Dict[str, any]:
        """
        Processes a raw query and returns a dictionary containing the
        spell-corrected query for display, and the final query vector.
        """
        logger.info(f"ğŸ“ Processing query for model '{self.model_type}': '{query}'")
        
        # 1. Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØµØ­Ø­ Ø¥Ù…Ù„Ø§Ø¦ÙŠØ§Ù‹ ÙÙ‚Ø· (Ù„Ù„Ø¹Ø±Ø¶)
        corrected_query_for_display = self.text_processor.get_spell_corrected_text(query)
        logger.info(f"âœ… Spell-corrected query for display: '{corrected_query_for_display}'")

        # 2. Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ (Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ØªØ¬Ù‡)
        fully_processed_query = self.text_processor._process_single_text(query)
        logger.info(f"âœ… Fully processed query for vectorization: '{fully_processed_query}'")

        query_vector = []
        if not fully_processed_query:
            # Handle empty query after processing
            if hasattr(self.vectorizer, 'get_sentence_embedding_dimension'): # BERT
                dim = self.vectorizer.get_sentence_embedding_dimension()
                query_vector = np.zeros((1, dim)).tolist()
            else: # TF-IDF
                dim = len(self.vectorizer.vocabulary_)
                query_vector = np.zeros((1, dim)).tolist()
        else:
            # 3. ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ Ø¥Ù„Ù‰ Ù…ØªØ¬Ù‡
            if self.model_type == 'tfidf':
                vector = self.vectorizer.transform([fully_processed_query])
                query_vector = vector.toarray().tolist()
            elif self.model_type == 'bert':
                vector = self.vectorizer.encode([fully_processed_query], normalize_embeddings=True)
                query_vector = vector.tolist()
            else:
                 raise NotImplementedError(f"Model type '{self.model_type}' not implemented.")

        # 4. Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù‚Ø§Ù…ÙˆØ³ Ø¨Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        return {
            "corrected_query_display": corrected_query_for_display,
            "query_vector": query_vector
        }
